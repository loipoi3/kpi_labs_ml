{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dcaa4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/loipoi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/loipoi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d9dcfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CustomMLPClassifier:\n",
    "    def __init__(self, learning_rate=0.01, num_epochs=100, hidden_layer_sizes=(100,)):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Convert input data and labels to appropriate formats\n",
    "        X = X.toarray()\n",
    "        y = np.array(y)\n",
    "        m = X.shape[0] # Number of training examples\n",
    "        self._w = []\n",
    "        self._b = []\n",
    "        \n",
    "        # Initialize weights and biases for each hidden layer\n",
    "        for layer_idx in range(len(self.hidden_layer_sizes)):\n",
    "            if layer_idx == 0:\n",
    "                n_in = X.shape[1]\n",
    "            else:\n",
    "                n_in = self.hidden_layer_sizes[layer_idx-1]\n",
    "            n_out = self.hidden_layer_sizes[layer_idx]\n",
    "            limit = np.sqrt(6 / (n_in + n_out))\n",
    "            self._w.append(np.random.uniform(-limit, limit, size=(n_in, n_out)))\n",
    "            self._b.append(0.0)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Forward propagation\n",
    "            cache = []\n",
    "            A = X\n",
    "            Z = []\n",
    "            for l in range(len(self._w)):\n",
    "                A_prev = A\n",
    "                \n",
    "                # Compute the linear transformation\n",
    "                Z.append(np.dot(A_prev, self._w[l]) + self._b[l])\n",
    "                linear_cache = (A_prev, self._w[l], self._b[l])\n",
    "                \n",
    "                if l != len(self._w) - 1:\n",
    "                    # Apply ReLU activation function for hidden layers\n",
    "                    A = np.maximum(0, Z[l])\n",
    "                else:\n",
    "                    # Apply sigmoid activation function for the output layer\n",
    "                    A = 1 / (1 + np.exp(-Z[l]))\n",
    "                activation_cache = Z[l]\n",
    "                cache.append((linear_cache, activation_cache))\n",
    "            \n",
    "            # Compute the BCEWithLogitsCost\n",
    "            cost = (-1 / m) * np.sum(y * np.log(A).T + (1 - y) * np.log(1 - A).T)\n",
    "\n",
    "            # Backpropagation\n",
    "            y = y.reshape(A.shape)\n",
    "            m = A.shape[0]\n",
    "            parameter_w = []\n",
    "            parameter_b = []\n",
    "            \n",
    "            dA = - (np.divide(y, A) - np.divide(1 - y, 1 - A))\n",
    "            \n",
    "            current_cache = cache[-1]\n",
    "            linear_cache, activation_cache = current_cache\n",
    "            Z = activation_cache\n",
    "            A_prev, W, b = linear_cache\n",
    "            \n",
    "            dZ = dA * (np.exp(-Z) / (1 + np.exp(-Z)) ** 2)\n",
    "            dA_prev = np.dot(W, dZ.T).T\n",
    "            dW = (1 / m) * np.dot(dZ.T, A_prev)\n",
    "            db = (1 / m) * np.sum(dZ, axis=0)\n",
    "            parameter_w.append(dW)\n",
    "            parameter_b.append(db)\n",
    "            \n",
    "            # Backpropagate through hidden layers\n",
    "            for l in reversed(range(len(self._w) - 1)):\n",
    "                current_cache = cache[l]\n",
    "                linear_cache, activation_cache = current_cache\n",
    "                Z = activation_cache\n",
    "                A_prev, W, b = linear_cache\n",
    "                m = A_prev.shape[0]\n",
    "                \n",
    "                dZ = dA_prev * np.int64(Z > 0) # Backpropagate through ReLU activation\n",
    "                dA_prev = np.dot(W, dZ.T).T\n",
    "                dW = (1 / m) * np.dot(dZ.T, A_prev)\n",
    "                db = (1 / m) * np.sum(dZ, axis=0)\n",
    "                parameter_w.append(dW)\n",
    "                parameter_b.append(db)\n",
    "            \n",
    "            # Update parameters using gradient descent\n",
    "            parameter_w = copy.deepcopy(parameter_w)\n",
    "            parameter_b = copy.deepcopy(parameter_b)\n",
    "            for l in range(len(self._w)):\n",
    "                self._w[l] = self._w[l] - self.learning_rate * parameter_w[-(l+1)].T\n",
    "                self._b[l] = self._b[l] - self.learning_rate * parameter_b[-(l+1)].T\n",
    "                \n",
    "            \n",
    "    def predict(self, X):\n",
    "        # Convert input data to the appropriate format\n",
    "        X = X.toarray()\n",
    "        m = X.shape[0]\n",
    "        y_prediction = np.zeros((m, 1))\n",
    "        A = X\n",
    "        A_prev = A\n",
    "        \n",
    "        # Forward propagation for prediction\n",
    "        for l in range(len(self._w)):\n",
    "            if l != len(self._w) - 1:\n",
    "                # Apply ReLU activation for hidden layers\n",
    "                A = np.maximum(0, np.dot(A_prev, self._w[l]) + self._b[l])\n",
    "            else:\n",
    "                # Apply sigmoid activation for the output layer\n",
    "                A = 1 / (1 + np.exp(-(np.dot(A_prev, self._w[l]) + self._b[l])))\n",
    "            A_prev = A\n",
    "        \n",
    "        # Convert probabilities to binary predictions (0 or 1)\n",
    "        for i in range(A.shape[0]):\n",
    "            if A[i, 0] > 0.5 :\n",
    "                y_prediction[i, 0] = 1\n",
    "            else:\n",
    "                y_prediction[i, 0] = 0\n",
    "                \n",
    "        return y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934e225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs (web links) from the text using regular expressions\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Remove mentions (usernames) from the text starting with '@' using regular expressions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\S+|\\(\\([A-Za-z0-9]+\\)\\)', '', text)\n",
    "    \n",
    "    # Remove any characters that are not alphabetic letters or whitespace using regular expressions\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Replace three or more consecutive same letters with two instances\n",
    "    text = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', text)\n",
    "    \n",
    "    # Remove special characters and punctuation\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d523815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_f1_score(y_true, y_pred):\n",
    "    # Ensure predictions are binary (0 or 1)\n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    # Calculate true positives, false positives, true negatives, and false negatives\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # Calculate precision and recall (avoid division by zero)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    # Calculate F1 score (avoid division by zero)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4adbc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      id sentiment\n",
       " 0    168  Positive\n",
       " 1     26  Positive\n",
       " 2     64  Positive\n",
       " 3     10  Positive\n",
       " 4    111  Negative\n",
       " ..   ...       ...\n",
       " 249  189  Positive\n",
       " 250   72  Positive\n",
       " 251  107  Positive\n",
       " 252  271  Positive\n",
       " 253  103  Positive\n",
       " \n",
       " [254 rows x 2 columns],\n",
       "       id                                               text\n",
       " 0    168  Hi Leah, I ordered this early to give to a co-...\n",
       " 1     26  Good evening, \\n  I just received my order! I ...\n",
       " 2     64  I couldn’t find where I could write a review b...\n",
       " 3     10  I received my order today and gave it to my si...\n",
       " 4    111  ﻿Max,\\n\\nWe received the heart but sadly are d...\n",
       " ..   ...                                                ...\n",
       " 249  189    Thank you, this is beautiful and they loved it.\n",
       " 250   72                    Thanks so much. They lookgreat!\n",
       " 251  107  Emily, \\n  THANK YOU so much for the new “bric...\n",
       " 252  271  Jacqueline,  \\n  I just received the replaceme...\n",
       " 253  103  Order #(857)982-509708\\nI just received my ord...\n",
       " \n",
       " [254 rows x 2 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(\"./data/labels.csv\")\n",
    "df_reviews = pd.read_csv(\"./data/reviews.csv\")\n",
    "df_labels, df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88abdf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hi Leah, I ordered this early to give to a co-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good evening, \\n  I just received my order! I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I couldn’t find where I could write a review b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I received my order today and gave it to my si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>﻿Max,\\n\\nWe received the heart but sadly are d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>Thank you, this is beautiful and they loved it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>Thanks so much. They lookgreat!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>Emily, \\n  THANK YOU so much for the new “bric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>Jacqueline,  \\n  I just received the replaceme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>Order #(857)982-509708\\nI just received my ord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                               text\n",
       "0            1  Hi Leah, I ordered this early to give to a co-...\n",
       "1            1  Good evening, \\n  I just received my order! I ...\n",
       "2            1  I couldn’t find where I could write a review b...\n",
       "3            1  I received my order today and gave it to my si...\n",
       "4            0  ﻿Max,\\n\\nWe received the heart but sadly are d...\n",
       "..         ...                                                ...\n",
       "249          1    Thank you, this is beautiful and they loved it.\n",
       "250          1                    Thanks so much. They lookgreat!\n",
       "251          1  Emily, \\n  THANK YOU so much for the new “bric...\n",
       "252          1  Jacqueline,  \\n  I just received the replaceme...\n",
       "253          1  Order #(857)982-509708\\nI just received my ord...\n",
       "\n",
       "[254 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.drop(\"id\", axis=1, inplace=True)\n",
    "df_reviews.drop(\"id\", axis=1, inplace=True)\n",
    "df = pd.concat([df_labels, df_reviews], axis=1)\n",
    "sentiment_mapping = {'Negative': 0, 'Positive': 1}\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map(sentiment_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7924ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      hi leah ordered early give coworker christmas ...\n",
       "1      good evening received order say moved tears de...\n",
       "2      couldnt find could write review stars way orde...\n",
       "3      received order today gave sister remind beauti...\n",
       "4      max received heart sadly disappointed two scra...\n",
       "                             ...                        \n",
       "249                                thank beautiful loved\n",
       "250                                thanks much lookgreat\n",
       "251    emily thank much new brick item jessica perfec...\n",
       "252    jacqueline received replacement base works per...\n",
       "253    order received order fantastic even better exp...\n",
       "Name: text, Length: 254, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1786428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    152\n",
       "0    102\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41e2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"sentiment\", axis=1, inplace=False), \n",
    "                                                    df[\"sentiment\"], test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31935774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer with specified parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['text'])\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b8c247b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = CustomMLPClassifier(learning_rate=0.1, num_epochs=10000, hidden_layer_sizes=(50, 80, 100, 70, 40, 1))\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c654e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9512195121951219"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = custom_f1_score(np.array(y_test).reshape(-1, 1), y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a8ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50, 80, 100, 70, 40),\n",
    "                               activation='relu',\n",
    "                               solver='adam',\n",
    "                               alpha=0.0001,\n",
    "                               learning_rate_init=0.1,\n",
    "                               max_iter=10000,\n",
    "                               random_state=42)\n",
    "mlp_classifier.fit(X_train_tfidf, y_train)\n",
    "y_pred = mlp_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e7b9095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = custom_f1_score(np.array(y_test).reshape(-1, 1), (y_pred > 0.5).astype(int).reshape(-1, 1))\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4936326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train_tfidf, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_tfidf)\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "num_round = 100\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "y_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc03e624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = custom_f1_score(np.array(y_test).reshape(-1, 1), (y_pred > 0.5).astype(int).reshape(-1, 1))\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9431b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
